<h2> Mean field theory deep learning papers </h2>

<ul>

     
          
             

 <li><a target="_blank" href="https://github.com/manjunath5496/Mean-field-theory-deep-learning-papers/blob/master/mft(1).pdf" style="text-decoration:none;">Deep Information Propagation</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Mean-field-theory-deep-learning-papers/blob/master/mft(2).pdf" style="text-decoration:none;">Resurrecting the sigmoid in deep learning through dynamical isometry: theory and practice</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Mean-field-theory-deep-learning-papers/blob/master/mft(3).pdf" style="text-decoration:none;">Mean Field Residual Networks: On the Edge of Chaos</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Mean-field-theory-deep-learning-papers/blob/master/mft(4).pdf" style="text-decoration:none;">The Emergence of Spectral Universality in Deep Networks</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Mean-field-theory-deep-learning-papers/blob/master/mft(5).pdf" style="text-decoration:none;">Universal Statistics of Fisher Information in Deep Neural Networks: Mean Field Approach</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Mean-field-theory-deep-learning-papers/blob/master/mft(6).pdf" style="text-decoration:none;">Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Mean-field-theory-deep-learning-papers/blob/master/mft(7).pdf" style="text-decoration:none;">Dynamical Isometry and a Mean Field Theory of RNNs: Gating Enables Signal Propagation in Recurrent Neural Networks</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Mean-field-theory-deep-learning-papers/blob/master/mft(8).pdf" style="text-decoration:none;"> Mean Field Analysis of Neural Networks: A Central Limit Theorem</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Mean-field-theory-deep-learning-papers/blob/master/mft(9).pdf" style="text-decoration:none;">Dynamical Isometry is Achieved in Residual Networks in a Universal Way for any Activation Function</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Mean-field-theory-deep-learning-papers/blob/master/mft(10).pdf" style="text-decoration:none;">Information Geometry of Orthogonal Initializations and Training</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Mean-field-theory-deep-learning-papers/blob/master/mft(11).pdf" style="text-decoration:none;">Dynamical Isometry and a Mean Field Theory of LSTMs and GRUs</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Mean-field-theory-deep-learning-papers/blob/master/mft(12).pdf" style="text-decoration:none;">Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Mean-field-theory-deep-learning-papers/blob/master/mft(13).pdf" style="text-decoration:none;">
A Mean Field Theory of Batch Normalization</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Mean-field-theory-deep-learning-papers/blob/master/mft(14).pdf" style="text-decoration:none;">Mean-field Analysis of Batch Normalization</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Mean-field-theory-deep-learning-papers/blob/master/mft(15).pdf" style="text-decoration:none;">Mean Field Analysis of Deep Neural Networks</a></li>

</ul>
